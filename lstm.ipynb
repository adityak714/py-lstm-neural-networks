{"cells":[{"cell_type":"markdown","metadata":{"id":"YoLhPjbGQbUo"},"source":["## **Stochastic Gradient Descent**\n","\n","From how we learned the conventional gradient descent algorithm (also known as **batch gradient descent**), this is an algorithm that drastically reduces the amount of computations done to find the minimum of the cost function $J(\\theta)$.\n","\n","Normal GD finds the sum of squared residuals for all $m$ data points. This would not scale well for, eg. 10000000 data points, and will be slow.\n","\n","> Stochastic Gradient Descent (SDG) computes the squared residual distance ($J(\\theta)=\\frac{(h_w(x)-y)^2}{m}$) for only one datapoint (rather than $\\Sigma ...$).\n","\n","Then, **cost is calculated, derivative is calculated, and is attempted to be minimized**. Repeat this process for another random datapoint, and another random datapoint, for a set number of iterations.\n","\n","Plus-sides:\n","- **Much faster**, and **efficient** than doing it for some iterations, and always adding $m$ terms in each iteration.\n","\n","**`Adam()`** - Pytorch / Tensorflow\n","- An algorithm very similar to Stochastic Gradient Descent, but a more efficient version."]},{"cell_type":"markdown","source":["### LSTM Neural Networks\n","- A neural network where flow of information occurs in a neural network, and using weighted parameters, knowledge from previous inputs is remembered in a state \"hidden state\" (**long term memory**). This is useful for influencing the output of the prediction."],"metadata":{"id":"VAzZEonP_bOv"}},{"cell_type":"code","source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.optim import Adam\n","!pip install pytorch_lightning\n","\n","import pytorch_lightning as L\n","from scipy import stats\n","from torch.utils.data import TensorDataset, DataLoader"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6fStpqvW_SVV","executionInfo":{"status":"ok","timestamp":1698424530472,"user_tz":-120,"elapsed":15351,"user":{"displayName":"Aditya Khadkikar","userId":"08725391876170109489"}},"outputId":"4a865bbf-bbb3-47b4-96d1-838a2c7c3aad"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pytorch_lightning\n","  Downloading pytorch_lightning-2.1.0-py3-none-any.whl (774 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.6/774.6 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (1.23.5)\n","Requirement already satisfied: torch>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (2.1.0+cu118)\n","Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.66.1)\n","Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (6.0.1)\n","Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (2023.6.0)\n","Collecting torchmetrics>=0.7.0 (from pytorch_lightning)\n","  Downloading torchmetrics-1.2.0-py3-none-any.whl (805 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m805.2/805.2 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (23.2)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.5.0)\n","Collecting lightning-utilities>=0.8.0 (from pytorch_lightning)\n","  Downloading lightning_utilities-0.9.0-py3-none-any.whl (23 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (2.31.0)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (3.8.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch_lightning) (3.12.4)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch_lightning) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch_lightning) (3.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch_lightning) (3.1.2)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch_lightning) (2.1.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (3.3.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.3.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.12.0->pytorch_lightning) (2.1.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (2023.7.22)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.12.0->pytorch_lightning) (1.3.0)\n","Installing collected packages: lightning-utilities, torchmetrics, pytorch_lightning\n","Successfully installed lightning-utilities-0.9.0 pytorch_lightning-2.1.0 torchmetrics-1.2.0\n"]}]},{"cell_type":"markdown","source":["## **Making By-Hand LSTM Model: Small-Scale Stock Predictor**\n","\n","Dataset from NYSE values of S&P500 companies: Kaggle\n","https://www.kaggle.com/datasets/dgawlik/nyse/data"],"metadata":{"id":"j2n4rR_Z9kvA"}},{"cell_type":"markdown","source":["### By-hand: Initializing model class"],"metadata":{"id":"-Yr_W2KK-RAv"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"OHgagLrOQbUs"},"outputs":[],"source":["class LSTMByHand(L.LightningModule):\n","    def __init__(self) -> None:\n","        ## Inherit all attributes from the LightningModule class\n","        super().__init__()\n","\n","        mean = torch.tensor(0.0) # Tensor is almost similar to a numpy-array\n","        std = torch.tensor(1.0)\n","\n","        ## Forget Gate\n","        self.w11 = nn.Parameter(torch.normal(mean, std), requires_grad=True) ## Randomly initialise a number from a Gaussian Normal Distribution\n","        self.w12 = nn.Parameter(torch.normal(mean, std), requires_grad=True)## mu = 0, sigma = 1 --> will return random numbers, most probably closer to 0 and less close to 1\n","        # Bias for the first gate\n","        self.b1 = nn.Parameter(torch.tensor(0.0), requires_grad=True)\n","\n","        ## Input Gate\n","        self.w21 = nn.Parameter(torch.normal(mean, std), requires_grad=True)\n","        self.w22 = nn.Parameter(torch.normal(mean, std), requires_grad=True)\n","        # Bias for the first gate\n","        self.b2 = nn.Parameter(torch.tensor(0.0), requires_grad=True)\n","\n","        ## Candidate Long-Term Memory\n","        self.w31 = nn.Parameter(torch.normal(mean, std), requires_grad=True)\n","        self.w32 = nn.Parameter(torch.normal(mean, std), requires_grad=True)\n","        # Bias for the first gate\n","        self.b3 = nn.Parameter(torch.tensor(0.0), requires_grad=True)\n","\n","        ## Output Gate\n","        self.w41 = nn.Parameter(torch.normal(mean, std), requires_grad=True)\n","        self.w42 = nn.Parameter(torch.normal(mean, std), requires_grad=True)\n","        # Bias for the first gate\n","        self.b4 = nn.Parameter(torch.tensor(0.0), requires_grad=True)\n","\n","    def lstm_unit(self, input_value, initial_short_memory, initial_long_memory):\n","        ## Forget gate\n","        # - input value x_t, and short-term memory is previous output, therefore h_t-1\n","        percent_longterm = torch.sigmoid((initial_short_memory * self.w11) + (input_value * self.w12) + self.b1)\n","\n","        ## Input gate --> Creates a new potential long-term memory, and what percentage of THAT to remember.\n","        # The line below is basically the forget gate for this part of the LSTM.\n","        percent_remember_potential = torch.sigmoid((initial_short_memory * self.w21) + (input_value * self.w22) + self.b2)\n","        # Below is not a % value, but the actual value of the new potential memory to be added [-1,1], and reduced down to how much ever percent_remember_potential says.\n","        potential_memory = torch.tanh((initial_short_memory * self.w31) + (input_value * self.w32) + self.b3)\n","\n","        ## Update long-term memory.\n","        # Add how much ever part of long_memory to keep, with how much ever part of new potential memory to add, and assign that as the updated value.\n","        updated_longterm = (percent_longterm * initial_long_memory) + (percent_remember_potential * potential_memory)\n","\n","        # NOTE: This is the core of LSTM, with every new input gone through, the long term memory is increased/scaled down as per influence, and from past information.\n","\n","        ## We use the updated long-term, and create a new short term memory.\n","        # This is again, controlled by its OWN forget gate, that decides how much info to keep, and how much to forget.\n","        percent_output = torch.sigmoid((initial_short_memory * self.w41) + (input_value * self.w42) + self.b4)\n","        updated_shortterm = torch.tanh(updated_longterm) * percent_output\n","\n","        ## We return the changed longterm memory and shortterm memories, which could be passed down further layers, or returned as output\n","        # (updated_shortterm would be the output).\n","        return([updated_longterm, updated_shortterm])\n","\n","    def forward(self, input: list):\n","        ## Initialise long + short term memory as 0\n","        long_memory = 0.0\n","        short_memory = 0.0\n","\n","        ## Assuming input is in sequential order, and in the form of a list, we iterate from the first index to the length of the array,\n","        # of m items.\n","        for i in range(len(input)):\n","            # We call our previously created lstm_unit function, that updates the long+short term memory based on how it learns from\n","            # the data, and gives an output.\n","            long_memory, short_memory = self.lstm_unit(input[i], short_memory, long_memory)\n","\n","        # REMEMBER: The short-term memory is our last recorded output, and is what is outputted during this activity.\n","        return short_memory\n","\n","    def configure_optimizers(self):\n","        # The algorithm of PyTorch that tries to optimize the w parameters while training the LSTM.\n","        return Adam(self.parameters())\n","\n","    def training_step(self, batch, batch_idx):\n","        # Here we calculate things like the loss, to get the training progress of the LSTM.\n","        input_i, label_i = batch\n","        output_i = self.forward(input_i[0])\n","\n","        ## Loss calculation\n","        loss = (output_i - label_i)**2\n","\n","        self.log(\"train_loss\", loss)\n","\n","        if (label_i == 0):\n","            self.log(\"out_0_companyA\", output_i)\n","        else:\n","            self.log(\"out_0_companyB\", output_i)\n","\n","        return loss"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3cCHjMvbQbUv","executionInfo":{"status":"ok","timestamp":1698413968875,"user_tz":-120,"elapsed":10,"user":{"displayName":"Aditya Khadkikar","userId":"08725391876170109489"}},"outputId":"e0cc5cfb-dcbd-40f5-f395-38bf527e496c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Company A: Expected: 0, Actual:  tensor(0.4607)\n","Company B: Expected: 1, Actual:  tensor(0.5484)\n"]}],"source":["## This is an example trial run of the LSTM, in action. Here, we simulate with a very small dataset, such as the stock market\n","# prices of a company, for 4 days.\n","\n","model = LSTMByHand()\n","data1 = torch.tensor([0., 0.5, 0.25, 1.])\n","data2 = torch.tensor([1., 0.5, 0.25, 1.])\n","\n","print(\"Company A: Expected: 0, Actual: \", model(data1).detach())\n","print(\"Company B: Expected: 1, Actual: \", model(data2).detach())"]},{"cell_type":"markdown","metadata":{"id":"7npGdqsQQbUw"},"source":["### Training of By-Hand LSTM\n","\n","As can be seen from running the cell above, the model is quite inaccurate, as it does not return a value close to the observed (true) value. So we train it using the following methods...\n","\n","Troubleshooting:\n","> If an error comes up, of the kind \"Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\", then add `.detach().numpy()` in all usages of Tensors, or go to `_tensors.py` in the `torch` library's source code, and modify the `__array__` function to return `self.detach().numpy()` instead of `self.numpy()`."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":364,"referenced_widgets":["b920f63a03934da6b8d9d10d8d959739","5735a362375641bd99347eb480ce12e6","e7c933fe5ea740a2b9c9b6d6ea4a3274","49571be62c3c4aa4b395111980bd9027","3986355311814c88a707710b378cb924","cd1f4b51e27a40e980e052ef94280f6a","6057fe2777ee47128943d237c0771d51","6c11557a7caf4c6aab3a6d5036d2dcb1","930868eb262b4f10940c5c1d3a6bb56c","5d2d2a7a36354f17ab01885c335ea53c","10de9848ee4446c8801ea286529afc51"]},"id":"6xGPjXb1QbUx","executionInfo":{"status":"ok","timestamp":1698413975926,"user_tz":-120,"elapsed":7059,"user":{"displayName":"Aditya Khadkikar","userId":"08725391876170109489"}},"outputId":"d4a1480d-169f-4540-d7af-237f6c29dd02"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n","INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:pytorch_lightning.callbacks.model_summary:\n","  | Name         | Type | Params\n","--------------------------------------\n","  | other params | n/a  | 12    \n","--------------------------------------\n","12        Trainable params\n","0         Non-trainable params\n","12        Total params\n","0.000     Total estimated model params size (MB)\n","/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=1` in the `DataLoader` to improve performance.\n","/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:293: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"]},{"output_type":"display_data","data":{"text/plain":["Training: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b920f63a03934da6b8d9d10d8d959739"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=100` reached.\n"]}],"source":["X = torch.tensor([[0., 0.5, 0.25, 1.], [1., 0.5, 0.25, 1.]], requires_grad=True)\n","y = torch.tensor([0., 1.], requires_grad=True)\n","\n","# Bring X and y together as one matrix, done as a \"TensorDataset\", which is passed in, like any other nd-numpy array.\n","dataset = TensorDataset(X, y)\n","\n","# Make the dataset be entered to a dataloader, for quick training, and sending data in parts (batches)\n","# while training etc.\n","dataloader = DataLoader(dataset)\n","\n","## Training Area - doing backpropagation for 2000 epochs\n","# Initialize trainer instance (only done once at start, and then comment out the line)\n","trainer = L.Trainer(max_epochs=100)\n","\n","# Allow model to retrain on an improved version, over and over, instead of resetting progress everytime.\n","model_last_checkpoint = trainer.checkpoint_callback.best_model_path\n","\n","## Uncomment this --> And run if model is to be further trained FROM WHERE IT LEFT OF\n","# trainer = L.Trainer(max_epochs=6000)\n","# run trainer on LSTM \"model\", and use the training data, supplied by the loader \"dataLoader\"\n","trainer.fit(model, train_dataloaders=dataloader)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"liW5Zu8LQbUx","executionInfo":{"status":"ok","timestamp":1698413976922,"user_tz":-120,"elapsed":13,"user":{"displayName":"Aditya Khadkikar","userId":"08725391876170109489"}},"outputId":"034be9ae-f11a-468d-d9ba-ef736b6354f8"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(0.3852, grad_fn=<MulBackward0>)\n","tensor(0.5548, grad_fn=<MulBackward0>)\n"]}],"source":["print(model(torch.tensor([0.,0.5,0.25,1.]))) # Should be a value very close to 0\n","print(model(torch.tensor([1.,0.5,0.25,1.]))) # Should be a value very close to 1"]},{"cell_type":"markdown","metadata":{"id":"ahSfWS6MQbUx"},"source":["### Visualize the changes in the loss, and how the learning is going\n","\n","We can use `TensorBoard` to be able to visualise, in the form of graphs, how the neural network is improving. There should be a directory with the name of `lightning_logs/` where 1) the above results that the model predicts, 2) the losses after each epoch etc. are stored.\n","\n","Run in a terminal:\n","```\n","tensorboard --logdir=lightning_logs/\n","```"]},{"cell_type":"markdown","metadata":{"id":"alH73vhQQbUz"},"source":["## **Extended exercise: Stock Predictor model using LSTM**\n","Here we will use the NYSE dataset, and put our LSTM to good use, by making it learn the closing prices of a particular company's stocks in a span of **1 week**, and use it to predict the price on the **8th day**. We will make m training examples, where m is the total number of collected time points (days, in this case it is data collected for about 1 year of prices), divided by 7 (as we group them into batches, to train the model with). The 8th column will represent the label, which is made to be the day that the closing price was observed to be (y)."]},{"cell_type":"markdown","source":["### Data Observation\n","Getting the NYSE dataset, and analysing the amount of entries made for each company. From collecting the frequencies, it was found that AAPL (Apple Inc.) was one of the popular ones, and had a lot of entries, which could be used for training the model well."],"metadata":{"id":"hYUq4lZ34mzM"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"U6AhOwPzQbUz"},"outputs":[],"source":["import pandas as pd\n","import scipy\n","import sklearn\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_2d8cupQQbU0"},"outputs":[],"source":["def loadDataSet(dirname: str, filename: str):\n","    return pd.read_csv(dirname+filename)"]},{"cell_type":"code","source":["!wget https://github.com/adityak714/rust_multithr-hotel-reserv-system/raw/main/archive.zip\n","!unzip archive.zip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3yTbOoV4Wvrd","executionInfo":{"status":"ok","timestamp":1698413984316,"user_tz":-120,"elapsed":7403,"user":{"displayName":"Aditya Khadkikar","userId":"08725391876170109489"}},"outputId":"c7a42040-7c9b-487e-f1ad-39b9a7598d19"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-10-27 13:39:35--  https://github.com/adityak714/rust_multithr-hotel-reserv-system/raw/main/archive.zip\n","Resolving github.com (github.com)... 20.205.243.166\n","Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/adityak714/rust_multithr-hotel-reserv-system/main/archive.zip [following]\n","--2023-10-27 13:39:35--  https://raw.githubusercontent.com/adityak714/rust_multithr-hotel-reserv-system/main/archive.zip\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 16177814 (15M) [application/zip]\n","Saving to: ‘archive.zip.4’\n","\n","archive.zip.4       100%[===================>]  15.43M  --.-KB/s    in 0.06s   \n","\n","2023-10-27 13:39:35 (271 MB/s) - ‘archive.zip.4’ saved [16177814/16177814]\n","\n","Archive:  archive.zip\n","replace archive/prices-split-adjusted.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"28DcBVOSQbU0","executionInfo":{"status":"ok","timestamp":1698413985636,"user_tz":-120,"elapsed":1330,"user":{"displayName":"Aditya Khadkikar","userId":"08725391876170109489"}},"outputId":"8b87fd18-ccf3-477c-adcc-db2e2cb96416"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['date', 'symbol', 'open', 'close', 'low', 'high', 'volume'], dtype='object')"]},"metadata":{},"execution_count":9}],"source":["prices_df = loadDataSet('./archive/','prices-split-adjusted.csv')\n","\n","prices_df.columns\n","\n","#fundamentals.columns\n","\n","#fundamentals.corr()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x02PaEbIQbU0","executionInfo":{"status":"ok","timestamp":1698415537162,"user_tz":-120,"elapsed":966,"user":{"displayName":"Aditya Khadkikar","userId":"08725391876170109489"}},"outputId":"a22f0e00-402e-42ec-c149-37e614ed1362"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["254      -1.724049\n","721      -1.722183\n","1189     -1.739383\n","1657     -1.741350\n","2125     -1.734288\n","            ...   \n","848767    1.310512\n","849267    1.336640\n","849767    1.318986\n","850267    1.317927\n","850767    1.285797\n","Name: close, Length: 1762, dtype: float64"]},"metadata":{},"execution_count":29}],"source":["wltw_prices = prices_df['close'].loc[prices_df['symbol'] == 'AAPL']\n","wltw_prices = stats.zscore(wltw_prices)\n","\n","wltw_prices # of type series"]},{"cell_type":"markdown","metadata":{"id":"jSNktb0hQbU0"},"source":["### Data Batching\n","\n","Split day-wise close figures, to **batches of 5-day data**. Then the 6th index, will be considered as our output (y), and shall be used to check with what the model predicts."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-HXmcFmwQbU0","executionInfo":{"status":"ok","timestamp":1698415542887,"user_tz":-120,"elapsed":556,"user":{"displayName":"Aditya Khadkikar","userId":"08725391876170109489"}},"outputId":"09c9e51d-b8b0-4797-ea9b-a9a70bb95e51"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[-1.72404938 -1.72218316 -1.73938285 -1.74134995 -1.73428846 -1.74372057]\n"," [-1.74715044 -1.76480409 -1.71885418 -1.73554946 -1.75401016 -1.80606319]\n"," [-1.75496846 -1.79829561 -1.83476297 -1.82129578 -1.81559618 -1.79859825]\n"," ...\n"," [ 1.12373679  1.14350881  1.13574117  1.13185733  1.09866839  1.06230191]\n"," [ 1.07854323  1.11667519  1.15516029  1.21977244  1.1968229   1.26355367]\n"," [ 1.29109333  1.31474915  1.32569434  1.32957818  1.30239166  1.3105122 ]]\n"]}],"source":["wltw_prices_list = wltw_prices.values.tolist()\n","\n","wltw_new = np.zeros((220,6))\n","j = 0\n","\n","for i in range(0, len(wltw_prices_list), 8):\n","    if len(wltw_prices_list[i:i+5]) < 5:\n","        break\n","    wltw_new[j,:5] = wltw_prices_list[i:i+5]\n","    wltw_new[j,5] = wltw_prices_list[i+5]\n","    j = j + 1\n","\n","print(wltw_new)"]},{"cell_type":"markdown","source":["### By-hand - Predicting stock prices of AAPL using self-made LSTM network"],"metadata":{"id":"5sgwKkgCzuGZ"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":364,"referenced_widgets":["a774c5410a9049228b7756186ab86312","9e1c815f472b4a9b90d0f7d8e956cdcc","8547f256f232489c9a05ec67f9ce3603","a6dcdb6114a140bd813563e799fbd747","04ad15b92fa640c78fdc95501d634f79","d917d11584354a03b00282f0599f8271","edff5f17868549a48b6e68bbc26ce49a","922d6529331248c68fe2ad38bd18e9b8","52187725f55945f5adddadf901368563","e2cd1b0644f344bbaff1c2c4ed5906d9","0d79c828f3624f2ab9d8d7fbc4099a02"]},"id":"DZWiflYFQbU1","executionInfo":{"status":"ok","timestamp":1698415549308,"user_tz":-120,"elapsed":1377,"user":{"displayName":"Aditya Khadkikar","userId":"08725391876170109489"}},"outputId":"5737ec0b-f47d-42e4-d2f1-1620b9eae4b5"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n","INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:pytorch_lightning.callbacks.model_summary:\n","  | Name         | Type | Params\n","--------------------------------------\n","  | other params | n/a  | 12    \n","--------------------------------------\n","12        Trainable params\n","0         Non-trainable params\n","12        Total params\n","0.000     Total estimated model params size (MB)\n","/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=1` in the `DataLoader` to improve performance.\n","/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:293: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"]},{"output_type":"display_data","data":{"text/plain":["Training: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a774c5410a9049228b7756186ab86312"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=20` reached.\n"]}],"source":["model_ = LSTMByHand()\n","\n","wltw_X = torch.tensor(wltw_new[:, :5], requires_grad=True)\n","wltw_y = torch.tensor(wltw_new[:, 5], requires_grad=True)\n","\n","dataset_ = TensorDataset(wltw_X, wltw_y)\n","dataloader_ = DataLoader(dataset_)\n","\n","## Training Area - doing backpropagation for 2000 epochs\n","# Initialize trainer instance (only done once at start, and then comment out the line)\n","trainer_ = L.Trainer(max_epochs=20)\n","\n","# Allow model to retrain on an improved version, over and over, instead of resetting progress everytime.\n","model_last_checkpoint = trainer_.checkpoint_callback.best_model_path\n","\n","## Uncomment this --> And run if model is to be further trained FROM WHERE IT LEFT OF\n","# trainer_ = L.Trainer(max_epochs=300)\n","# run trainer on LSTM \"model\", and use the training data, supplied by the loader \"dataLoader\"\n","trainer_.fit(model_, train_dataloaders=dataloader)"]},{"cell_type":"markdown","source":["### Pytorch - Predicting stock prices of AAPL using `torch.nn.LSTM()`"],"metadata":{"id":"3KOaSWQT3qOs"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"kvvAzkjOQbU1"},"outputs":[],"source":["class LSTM(L.LightningModule):\n","    def __init__(self) -> None:\n","        super().__init__()\n","        self.lstm = torch.nn.LSTM(input_size=1, hidden_size=1)\n","\n","    def forward(self, input):\n","        input_trans = input.view(len(input), 1)\n","        lstm_out, temp = self.lstm(input_trans)\n","\n","        prediction = lstm_out[-1]\n","        return prediction\n","\n","    def configure_optimizers(self):\n","        return Adam(self.parameters(), lr=0.0001)\n","\n","    def training_step(self, batch, batch_idx):\n","        # Here we calculate things like the loss, to get the training progress of the LSTM.\n","        input_i, label_i = batch\n","        output_i = self.forward(input_i[0])\n","\n","        ## Loss calculation\n","        loss_func = nn.MSELoss()\n","        loss = loss_func(input_i, output_i)\n","        loss.backward(retain_graph=True)\n","\n","        self.log(\"train_loss\", loss)\n","        self.log(\"pred_closing\", output_i)\n","\n","        loss_ = (output_i-label_i)**2\n","\n","        return loss_"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":989,"referenced_widgets":["10a79d0d42ed468693b771fc118d5d73","15f649a96bbf468389132d171f2eff7c","6896c62cead94b199282eaedc80ac706","d55acbac2f21486a9ba485055ee717c5","aa06645dc7854e9e800448dbac5b5a4b","21a57a669931491ab6f3a3a0e1891546","1c14c53910ef4fcebb5c0f1254dc84c3","1728619623254be8869fd2bc72ef59af","ff3ab6b9887443ac993d8554082b4548","f0c6a051df524ff488e0dbae0448409c","6be7bf292b9b4ffba431402700f63d7f"]},"id":"mJsEjHPRQbU2","executionInfo":{"status":"ok","timestamp":1698415909711,"user_tz":-120,"elapsed":274447,"user":{"displayName":"Aditya Khadkikar","userId":"08725391876170109489"}},"outputId":"f5de68db-5e81-43be-ad75-c0382c04e0c6"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n","INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:pytorch_lightning.callbacks.model_summary:\n","  | Name | Type | Params\n","------------------------------\n","0 | lstm | LSTM | 16    \n","------------------------------\n","16        Trainable params\n","0         Non-trainable params\n","16        Total params\n","0.000     Total estimated model params size (MB)\n"]},{"output_type":"stream","name":"stdout","text":["tensor([[-1.7240, -1.7222, -1.7394, -1.7413, -1.7343],\n","        [-1.7472, -1.7648, -1.7189, -1.7355, -1.7540],\n","        [-1.7550, -1.7983, -1.8348, -1.8213, -1.8156],\n","        ...,\n","        [ 1.1237,  1.1435,  1.1357,  1.1319,  1.0987],\n","        [ 1.0785,  1.1167,  1.1552,  1.2198,  1.1968],\n","        [ 1.2911,  1.3147,  1.3257,  1.3296,  1.3024]],\n","       grad_fn=<ToCopyBackward0>)\n","tensor([-1.7437, -1.8061, -1.7986, -1.7776, -1.7714, -1.6694, -1.6699, -1.6133,\n","        -1.5643, -1.4442, -1.5614, -1.5306, -1.5078, -1.5399, -1.4222, -1.5580,\n","        -1.5352, -1.4715, -1.4916, -1.5270, -1.5803, -1.4749, -1.3521, -1.3981,\n","        -1.2787, -1.2497, -1.2039, -1.2878, -1.2341, -1.1866, -1.1634, -1.1325,\n","        -1.0458, -1.0724, -1.0119, -1.0353, -0.9899, -1.0612, -1.0304, -1.0985,\n","        -1.1297, -1.0375, -1.0521, -1.1168, -1.0712, -1.1554, -1.1287, -0.9892,\n","        -0.8520, -0.8023, -0.9186, -0.9191, -0.9168, -0.8214, -0.7897, -0.9383,\n","        -0.7929, -0.7618, -0.8605, -0.9044, -0.8212, -0.8922, -0.7726, -0.6687,\n","        -0.6477, -0.5079, -0.2338, -0.1516, -0.0698,  0.2529,  0.2206,  0.3377,\n","         0.0225,  0.0476, -0.0491,  0.0830,  0.1236,  0.1509,  0.1851,  0.2479,\n","         0.0966,  0.3366,  0.4061,  0.6001,  0.5393,  0.7207,  0.5321,  0.3727,\n","         0.3077,  0.0110,  0.0500,  0.1486, -0.0848, -0.1798, -0.1610, -0.2680,\n","        -0.4993, -0.3828, -0.5297, -0.6565, -0.5049, -0.5708, -0.6059, -0.7926,\n","        -0.5563, -0.5647, -0.5582, -0.5919, -0.6257, -0.8034, -0.6483, -0.6902,\n","        -0.4705, -0.2891, -0.2666, -0.2905, -0.4597, -0.3988, -0.3338, -0.1813,\n","        -0.1805, -0.1775, -0.1618,  0.0212, -0.0255,  0.0262, -0.1013, -0.0492,\n","        -0.2180, -0.0496, -0.1492, -0.0969, -0.0839, -0.0859, -0.1910,  0.1930,\n","         0.1623,  0.2466,  0.3674,  0.4550,  0.3840,  0.5849,  0.4833,  0.6700,\n","         0.5415,  0.7474,  0.8437,  0.7858,  0.7890,  0.7138,  0.5952,  0.9652,\n","         1.0454,  1.2452,  1.2438,  1.0708,  1.1513,  1.0009,  1.0351,  1.3331,\n","         1.6057,  1.8631,  1.6664,  1.7324,  1.6583,  1.6841,  1.7377,  1.7406,\n","         1.7494,  1.8585,  1.7088,  1.7116,  1.6251,  1.6332,  1.6156,  1.2441,\n","         1.2907,  1.0694,  1.1619,  1.2021,  1.0909,  1.1368,  1.2745,  1.5241,\n","         1.1629,  1.3638,  1.3709,  0.9401,  0.9130,  0.6351,  0.7269,  0.5161,\n","         0.5952,  0.7459,  0.8070,  0.9437,  1.0736,  1.0750,  0.6503,  0.4727,\n","         0.5225,  0.6729,  0.6333,  0.5895,  0.5694,  0.7212,  0.8805,  1.0383,\n","         1.0577,  0.9426,  1.0079,  1.1760,  1.1880,  1.3469,  1.2385,  1.1177,\n","         1.0824,  1.0623,  1.2636,  1.3105], grad_fn=<ToCopyBackward0>)\n"]},{"output_type":"display_data","data":{"text/plain":["Training: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10a79d0d42ed468693b771fc118d5d73"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=250` reached.\n"]}],"source":["model_ = LSTM()\n","wltw_X = (torch.tensor(stats.zscore(wltw_new[:, :5], axis=None), requires_grad=True).float())\n","wltw_y = (torch.tensor(stats.zscore(wltw_new[:, 5], axis=None), requires_grad=True).float())\n","\n","print(wltw_X)\n","print(wltw_y)\n","\n","dataset_ = TensorDataset(wltw_X, wltw_y)\n","dataloader_ = DataLoader(dataset_)\n","\n","trainer2 = L.Trainer(max_epochs=250, log_every_n_steps=5)\n","trainer2.fit(model_, dataloader_)"]},{"cell_type":"markdown","source":["### Retraining from where the model last left off\n","Only run if the above is true."],"metadata":{"id":"GmVNAHDh3fEm"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":434,"referenced_widgets":["ecc322af74be43f7b3cbd7f023469ea0","a20905263b9c4e0084cb99158ec87587","01f6500430d44c7bb793e0a65cf466ba","b8c6f9513e6f4b21aa93f33008a18706","7bf42e6b9ccc47fd8edc66817596bffb","296611ac8c7547a68daeb8bd51c5f60c","e60c3cb71b0645008000d2c361b8e47a","8db447da867249d597f4298b4100be67","131c42800f044770ae35abf417a82bec","cdea027803ef49c181cb0d534ce1217e","eef7baddfa22423a992edf9348b75ccd"]},"id":"174aDw7lQbU3","executionInfo":{"status":"ok","timestamp":1698416964156,"user_tz":-120,"elapsed":279158,"user":{"displayName":"Aditya Khadkikar","userId":"08725391876170109489"}},"outputId":"b92c3c20-b8db-4911-f714-d4d3a529db18"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n","INFO:pytorch_lightning.utilities.rank_zero:Restoring states from the checkpoint path at /content/lightning_logs/version_10/checkpoints/epoch=249-step=55000.ckpt\n","/usr/local/lib/python3.10/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:345: The dirpath has changed from '/content/lightning_logs/version_10/checkpoints' to '/content/lightning_logs/version_11/checkpoints', therefore `best_model_score`, `kth_best_model_path`, `kth_value`, `last_model_path` and `best_k_models` won't be reloaded. Only `best_model_path` will be reloaded.\n","INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:pytorch_lightning.callbacks.model_summary:\n","  | Name | Type | Params\n","------------------------------\n","0 | lstm | LSTM | 16    \n","------------------------------\n","16        Trainable params\n","0         Non-trainable params\n","16        Total params\n","0.000     Total estimated model params size (MB)\n","INFO:pytorch_lightning.utilities.rank_zero:Restored all states from the checkpoint at /content/lightning_logs/version_10/checkpoints/epoch=249-step=55000.ckpt\n","/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=1` in the `DataLoader` to improve performance.\n"]},{"output_type":"display_data","data":{"text/plain":["Training: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ecc322af74be43f7b3cbd7f023469ea0"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=500` reached.\n"]}],"source":["model_last_checkpoint2 = trainer2.checkpoint_callback.best_model_path\n","\n","## Uncomment this --> And run if model is to be further trained FROM WHERE IT LEFT OF\n","trainer2 = L.Trainer(max_epochs=500, log_every_n_steps=5)\n","# run trainer on LSTM \"model\", and use the training data, supplied by the loader \"dataLoader\"\n","\n","wltw_X = torch.tensor(wltw_new[:, :5], requires_grad=True).float()\n","wltw_y = torch.tensor(wltw_new[:, 5], requires_grad=True).float()\n","\n","new_dataloader = DataLoader(TensorDataset(wltw_X, wltw_y))\n","\n","trainer2.fit(model_, dataloader_, ckpt_path=model_last_checkpoint2)"]},{"cell_type":"markdown","source":["### Accuracy of Model"],"metadata":{"id":"Nrl_cYTP3lD5"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7tsOCLA-QbU3","executionInfo":{"status":"ok","timestamp":1698418218055,"user_tz":-120,"elapsed":7,"user":{"displayName":"Aditya Khadkikar","userId":"08725391876170109489"}},"outputId":"81cd4404-607f-4b97-cfc6-ee843db5c566"},"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted: \n","0.9722046504895187\n"]}],"source":["print(\"Predicted: \")\n","\n","pred_ = np.zeros((wltw_new.shape[0]))\n","real_ = np.zeros((wltw_new.shape[0]))\n","\n","for i in range(wltw_new.shape[0]):\n","  pred_[i] = model_(torch.tensor((wltw_new[i, :5])).float()).detach().numpy().item()\n","  real_[i] = (wltw_new[i, 5])\n","\n","accuracy = np.sum(pred_/real_)/wltw_new.shape[0]\n","print(accuracy)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.16"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"b920f63a03934da6b8d9d10d8d959739":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5735a362375641bd99347eb480ce12e6","IPY_MODEL_e7c933fe5ea740a2b9c9b6d6ea4a3274","IPY_MODEL_49571be62c3c4aa4b395111980bd9027"],"layout":"IPY_MODEL_3986355311814c88a707710b378cb924"}},"5735a362375641bd99347eb480ce12e6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cd1f4b51e27a40e980e052ef94280f6a","placeholder":"​","style":"IPY_MODEL_6057fe2777ee47128943d237c0771d51","value":"Epoch 99: 100%"}},"e7c933fe5ea740a2b9c9b6d6ea4a3274":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c11557a7caf4c6aab3a6d5036d2dcb1","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_930868eb262b4f10940c5c1d3a6bb56c","value":2}},"49571be62c3c4aa4b395111980bd9027":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d2d2a7a36354f17ab01885c335ea53c","placeholder":"​","style":"IPY_MODEL_10de9848ee4446c8801ea286529afc51","value":" 2/2 [00:00&lt;00:00, 57.20it/s, v_num=5]"}},"3986355311814c88a707710b378cb924":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"cd1f4b51e27a40e980e052ef94280f6a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6057fe2777ee47128943d237c0771d51":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6c11557a7caf4c6aab3a6d5036d2dcb1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"930868eb262b4f10940c5c1d3a6bb56c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5d2d2a7a36354f17ab01885c335ea53c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"10de9848ee4446c8801ea286529afc51":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a774c5410a9049228b7756186ab86312":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9e1c815f472b4a9b90d0f7d8e956cdcc","IPY_MODEL_8547f256f232489c9a05ec67f9ce3603","IPY_MODEL_a6dcdb6114a140bd813563e799fbd747"],"layout":"IPY_MODEL_04ad15b92fa640c78fdc95501d634f79"}},"9e1c815f472b4a9b90d0f7d8e956cdcc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d917d11584354a03b00282f0599f8271","placeholder":"​","style":"IPY_MODEL_edff5f17868549a48b6e68bbc26ce49a","value":"Epoch 19: 100%"}},"8547f256f232489c9a05ec67f9ce3603":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_922d6529331248c68fe2ad38bd18e9b8","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_52187725f55945f5adddadf901368563","value":2}},"a6dcdb6114a140bd813563e799fbd747":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e2cd1b0644f344bbaff1c2c4ed5906d9","placeholder":"​","style":"IPY_MODEL_0d79c828f3624f2ab9d8d7fbc4099a02","value":" 2/2 [00:00&lt;00:00, 57.75it/s, v_num=9]"}},"04ad15b92fa640c78fdc95501d634f79":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"d917d11584354a03b00282f0599f8271":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"edff5f17868549a48b6e68bbc26ce49a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"922d6529331248c68fe2ad38bd18e9b8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52187725f55945f5adddadf901368563":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e2cd1b0644f344bbaff1c2c4ed5906d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d79c828f3624f2ab9d8d7fbc4099a02":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"10a79d0d42ed468693b771fc118d5d73":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_15f649a96bbf468389132d171f2eff7c","IPY_MODEL_6896c62cead94b199282eaedc80ac706","IPY_MODEL_d55acbac2f21486a9ba485055ee717c5"],"layout":"IPY_MODEL_aa06645dc7854e9e800448dbac5b5a4b"}},"15f649a96bbf468389132d171f2eff7c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_21a57a669931491ab6f3a3a0e1891546","placeholder":"​","style":"IPY_MODEL_1c14c53910ef4fcebb5c0f1254dc84c3","value":"Epoch 249: 100%"}},"6896c62cead94b199282eaedc80ac706":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1728619623254be8869fd2bc72ef59af","max":220,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ff3ab6b9887443ac993d8554082b4548","value":220}},"d55acbac2f21486a9ba485055ee717c5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f0c6a051df524ff488e0dbae0448409c","placeholder":"​","style":"IPY_MODEL_6be7bf292b9b4ffba431402700f63d7f","value":" 220/220 [00:01&lt;00:00, 211.00it/s, v_num=10]"}},"aa06645dc7854e9e800448dbac5b5a4b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"21a57a669931491ab6f3a3a0e1891546":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c14c53910ef4fcebb5c0f1254dc84c3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1728619623254be8869fd2bc72ef59af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff3ab6b9887443ac993d8554082b4548":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f0c6a051df524ff488e0dbae0448409c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6be7bf292b9b4ffba431402700f63d7f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ecc322af74be43f7b3cbd7f023469ea0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a20905263b9c4e0084cb99158ec87587","IPY_MODEL_01f6500430d44c7bb793e0a65cf466ba","IPY_MODEL_b8c6f9513e6f4b21aa93f33008a18706"],"layout":"IPY_MODEL_7bf42e6b9ccc47fd8edc66817596bffb"}},"a20905263b9c4e0084cb99158ec87587":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_296611ac8c7547a68daeb8bd51c5f60c","placeholder":"​","style":"IPY_MODEL_e60c3cb71b0645008000d2c361b8e47a","value":"Epoch 499: 100%"}},"01f6500430d44c7bb793e0a65cf466ba":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8db447da867249d597f4298b4100be67","max":220,"min":0,"orientation":"horizontal","style":"IPY_MODEL_131c42800f044770ae35abf417a82bec","value":220}},"b8c6f9513e6f4b21aa93f33008a18706":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cdea027803ef49c181cb0d534ce1217e","placeholder":"​","style":"IPY_MODEL_eef7baddfa22423a992edf9348b75ccd","value":" 220/220 [00:01&lt;00:00, 205.66it/s, v_num=11]"}},"7bf42e6b9ccc47fd8edc66817596bffb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"296611ac8c7547a68daeb8bd51c5f60c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e60c3cb71b0645008000d2c361b8e47a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8db447da867249d597f4298b4100be67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"131c42800f044770ae35abf417a82bec":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cdea027803ef49c181cb0d534ce1217e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eef7baddfa22423a992edf9348b75ccd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}